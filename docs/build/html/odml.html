<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="Applying LoRA/QLoRA" href="lora.html" /><link rel="prev" title="Post-Training Quantization (PTQ)" href="ptq.html" />

    <!-- Generated with Sphinx 8.2.3 and Furo 2024.08.06 -->
        <title>ODML Quantization - qwix documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css?v=a5c4661c" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">qwix  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  <span class="sidebar-brand-text">qwix  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Get Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics.html">Quantization Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="qat.html">Quantization-Aware Training (QAT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ptq.html">Post-Training Quantization (PTQ)</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">ODML Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="lora.html">Applying LoRA/QLoRA</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="_sources/odml.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="odml-quantization">
<span id="id1"></span><h1>ODML Quantization<a class="headerlink" href="#odml-quantization" title="Link to this heading">¶</a></h1>
<p>A distinct feature of Qwix is its ODML support. It’s able to quantize every op,
perform QAT, and export full-integer LiteRT models.</p>
<section id="xla-targets-vs-odml-targets">
<h2>XLA targets vs ODML targets<a class="headerlink" href="#xla-targets-vs-odml-targets" title="Link to this heading">¶</a></h2>
<p>Quantization for XLA targets and ODML targets are different due to their
different hardware characteristics. XLA devices are more versatile and powerful,
as they are also designed for training. Quantizing the matmul and convolution
ops is usually sufficient for these platforms; quantizing the remaining
element-wise ops typically offers negligible benefits.</p>
<p>In contrast, ODML devices are inexpensive and have diverse runtimes specifically
for quantized inference. Quantized inputs with static ranges are usually
required by kernels in those runtimes, and they generate quantized outputs with
static ranges too. Some of those runtimes lack floating point MXUs,
necessitating static quantization for every operator. Fusion is also common in
ODML runtimes. For example, a matmul kernel can often fuse the subsequent
addition and ReLU.</p>
<p>The illustration shows how a dense layer is quantized differently on XLA targets
vs ODML targets.</p>
<div class="flex-container text-center docutils container">
<div class="graphviz"><img src="_images/graphviz-e495266214ce5552193946f1942c7347f2c83fa6.png" alt="digraph {
  graph [label=&quot;Unquantized model&quot; ordering=&quot;in&quot; rankdir=LR]
  node [color=&quot;none&quot; style=&quot;filled&quot;]

  matmul [color=lightskyblue]
  add [color=lightskyblue]
  relu [color=lightskyblue]

  input -&gt; matmul -&gt; add -&gt; relu -&gt; output
  weight -&gt; matmul
  bias -&gt; add [ordering=in]
}" class="graphviz" /></div>
<div class="graphviz"><img src="_images/graphviz-17fed0352c69bcaa5e255506e06502c9379d0400.png" alt="digraph {
  graph [label=&quot;XLA targets&quot; ordering=&quot;in&quot; rankdir=LR]
  node [color=&quot;none&quot; style=&quot;filled&quot;]

  qw [label=&quot;quantized\nweight&quot;]
  qx [label=&quot;quantize&quot; color=&quot;burlywood1&quot;]
  dq [label=&quot;dequantize&quot; color=&quot;burlywood1&quot;]
  int_op [label=&quot;int\nmatmul&quot; color=lightskyblue]
  add [color=lightskyblue]
  relu [color=lightskyblue]

  input -&gt; qx -&gt; int_op
  qw -&gt; int_op
  int_op -&gt; dq -&gt; add -&gt; relu -&gt; output
  bias -&gt; add
}" class="graphviz" /></div>
<div class="graphviz"><img src="_images/graphviz-d53b04967dfba7bcb55d318ec6b9a6c9886ca03f.png" alt="digraph {
  graph [label=&quot;ODML targets&quot; ordering=&quot;in&quot; rankdir=LR]
  node [color=&quot;none&quot; style=&quot;filled&quot;]

  qx [label=&quot;quantized\ninput&quot;]
  qw [label=&quot;quantized\nweight&quot; rank=0]
  bias [label=&quot;quantized\nbias&quot;]
  output [label=&quot;quantized\noutput&quot;]
  int_op [label=&quot;quantized\nmatmul+add+relu&quot; color=lightskyblue]

  qx -&gt; int_op -&gt; output
  qw -&gt; int_op
  bias -&gt; int_op
}" class="graphviz" /></div>
</div>
<p>The other difference is how the models get deployed. For XLA targets, models are
either served directly in Python, or exported as saved models. Quantization is
completely done in the framework. For ODML targets, models need to undergo
LiteRT conversion, which allows transforming the graph for quantization. The
transformation during the conversion is more powerful as it has access to the
whole graph and can perform propagation and fusion easily. However, the
framework must provide enough annotations in the graph for the converter, where
a protocol is needed between the framework and the ODML converter.</p>
</section>
<section id="odml-quantization-with-qwix">
<h2>ODML quantization with Qwix<a class="headerlink" href="#odml-quantization-with-qwix" title="Link to this heading">¶</a></h2>
<p>ODML quantization in Qwix is implemented by <code class="docutils literal notranslate"><span class="pre">OdmlQatProvider</span></code> and
<code class="docutils literal notranslate"><span class="pre">OdmlConversionProvider</span></code>. <strong>Asymmetric</strong>
<a class="reference internal" href="basics.html#srq"><span class="std std-ref">static-range quantization</span></a> is enabled by default for ODML
targets.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rules</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">qwix</span><span class="o">.</span><span class="n">QuantizationRule</span><span class="p">(</span>
        <span class="n">weight_qtype</span><span class="o">=</span><span class="s1">&#39;int8&#39;</span><span class="p">,</span>
        <span class="n">act_qtype</span><span class="o">=</span><span class="s1">&#39;int8&#39;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">]</span>
</pre></div>
</div>
<section id="odml-qat">
<h3>ODML QAT<a class="headerlink" href="#odml-qat" title="Link to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">OdmlQatProvider</span></code> is very similar to <code class="docutils literal notranslate"><span class="pre">QatProvder</span></code> as it also inserts
<code class="docutils literal notranslate"><span class="pre">FakeQuant</span></code> op in the graph. The differences are</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">OdmlQatProvider</span></code> supports many more ops and actually should support every</dt><dd><p>op in the model.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">OdmlQatProvider</span></code> is aware of the fusion pattern and will skip inserting</dt><dd><p><code class="docutils literal notranslate"><span class="pre">FakeQuant</span></code> between e.g. matmul and add.</p>
</dd>
</dl>
</li>
</ul>
<p>To ensure all ops are quantized, the <code class="docutils literal notranslate"><span class="pre">OdmlQatProvider</span></code> has a strict mode that
will raise an error if an unsupported op is detected.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Linen</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">NNX</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fp_model</span> <span class="o">=</span> <span class="n">SomeLinenModel</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">provider</span> <span class="o">=</span> <span class="n">qwix</span><span class="o">.</span><span class="n">OdmlQatProvider</span><span class="p">(</span><span class="n">rules</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">qat_model</span> <span class="o">=</span> <span class="n">qwix</span><span class="o">.</span><span class="n">quantize_model</span><span class="p">(</span><span class="n">fp_model</span><span class="p">,</span> <span class="n">provider</span><span class="p">)</span>
<span class="c1"># qat_model can be trained as usual.</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fp_model</span> <span class="o">=</span> <span class="n">SomeNNXModel</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">provider</span> <span class="o">=</span> <span class="n">qwix</span><span class="o">.</span><span class="n">OdmlQatProvider</span><span class="p">(</span><span class="n">rules</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">qat_model</span> <span class="o">=</span> <span class="n">qwix</span><span class="o">.</span><span class="n">quantize_model</span><span class="p">(</span><span class="n">fp_model</span><span class="p">,</span> <span class="n">provider</span><span class="p">,</span> <span class="n">model_input</span><span class="p">)</span>
<span class="c1"># qat_model can be trained as usual.</span>
</pre></div>
</div>
</div></div>
</section>
<section id="odml-conversion">
<h3>ODML conversion<a class="headerlink" href="#odml-conversion" title="Link to this heading">¶</a></h3>
<p>After QAT, the ODML conversion can be achieved by applying the
<code class="docutils literal notranslate"><span class="pre">OdmlConversionProvider</span></code> to the model. The <code class="docutils literal notranslate"><span class="pre">OdmlConversionProvider</span></code> takes two
more arguments, the <code class="docutils literal notranslate"><span class="pre">params</span></code> and the <code class="docutils literal notranslate"><span class="pre">quant_stats</span></code>, because it needs to
calculate static scales for weights and activations during conversion.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">Linen</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">NNX</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">qat_variables</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># from QAT.</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">qat_variables</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span>
<span class="n">quant_stats</span> <span class="o">=</span> <span class="n">qat_variables</span><span class="p">[</span><span class="s1">&#39;quant_stats&#39;</span><span class="p">]</span>

<span class="n">conversion_provider</span> <span class="o">=</span> <span class="n">qwix</span><span class="o">.</span><span class="n">OdmlConversionProvider</span><span class="p">(</span><span class="n">rules</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">quant_stats</span><span class="p">)</span>
<span class="n">conversion_model</span> <span class="o">=</span> <span class="n">qwix</span><span class="o">.</span><span class="n">quantize_model</span><span class="p">(</span><span class="n">fp_model</span><span class="p">,</span> <span class="n">conversion_provider</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="admonition note">
<p class="admonition-title">Note</p>
<p>NNX support for ODML modes is experimental. The API is not finalized.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">qat_model</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># from QAT.</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">nnx</span><span class="o">.</span><span class="n">to_pure_dict</span><span class="p">(</span><span class="n">nnx</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="n">qat_model</span><span class="p">,</span> <span class="n">nnx</span><span class="o">.</span><span class="n">Param</span><span class="p">))</span>
<span class="n">quant_stats</span> <span class="o">=</span> <span class="n">nnx</span><span class="o">.</span><span class="n">to_pure_dict</span><span class="p">(</span><span class="n">nnx</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="n">qat_model</span><span class="p">,</span> <span class="n">qwix</span><span class="o">.</span><span class="n">QuantStat</span><span class="p">)),</span>

<span class="n">conversion_provider</span> <span class="o">=</span> <span class="n">qwix</span><span class="o">.</span><span class="n">OdmlConversionProvider</span><span class="p">(</span><span class="n">rules</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">quant_stats</span><span class="p">)</span>
<span class="n">conversion_model</span> <span class="o">=</span> <span class="n">qwix</span><span class="o">.</span><span class="n">quantize_model</span><span class="p">(</span><span class="n">fp_model</span><span class="p">,</span> <span class="n">conversion_provider</span><span class="p">,</span> <span class="n">model_input</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<p>The model can then be converted and exported using
<a class="reference external" href="https://ai.google.dev/edge">Google AI Edge</a>.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">Linen</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">NNX</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">ai_edge_jax</span>

<span class="n">litert_model</span> <span class="o">=</span> <span class="n">ai_edge_jax</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span>
    <span class="n">conversion_model</span><span class="o">.</span><span class="n">apply</span><span class="p">,</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">params</span><span class="p">},</span>
    <span class="p">(</span><span class="n">model_input</span><span class="p">,),</span>
    <span class="n">_litert_converter_flags</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;_experimental_strict_qdq&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>  <span class="c1"># necessary for Qwix.</span>
<span class="p">)</span>

<span class="c1"># Evaluate the LiteRT model on the host.</span>
<span class="n">litert_result</span> <span class="o">=</span> <span class="n">litert_model</span><span class="p">(</span><span class="n">model_input</span><span class="p">)</span>
<span class="c1"># Export the LiteRT model.</span>
<span class="n">litert_model</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s1">&#39;/tmp/litert_model.tflite&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">ai_edge_jax</span>

<span class="n">graphdef</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">nnx</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">conversion_model</span><span class="p">)</span>
<span class="n">litert_model</span> <span class="o">=</span> <span class="n">ai_edge_jax</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">nnx</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">graphdef</span><span class="p">,</span> <span class="n">params</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">),</span>
    <span class="n">state</span><span class="p">,</span>
    <span class="p">(</span><span class="n">model_input</span><span class="p">,),</span>
    <span class="n">_litert_converter_flags</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;_experimental_strict_qdq&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>  <span class="c1"># necessary for Qwix.</span>
<span class="p">)</span>

<span class="c1"># Evaluate the LiteRT model on the host.</span>
<span class="n">litert_result</span> <span class="o">=</span> <span class="n">litert_model</span><span class="p">(</span><span class="n">model_input</span><span class="p">)</span>
<span class="c1"># Export the LiteRT model.</span>
<span class="n">litert_model</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s1">&#39;/tmp/litert_model.tflite&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="lora.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Applying LoRA/QLoRA</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="ptq.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Post-Training Quantization (PTQ)</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, The qwix Authors
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">ODML Quantization</a><ul>
<li><a class="reference internal" href="#xla-targets-vs-odml-targets">XLA targets vs ODML targets</a></li>
<li><a class="reference internal" href="#odml-quantization-with-qwix">ODML quantization with Qwix</a><ul>
<li><a class="reference internal" href="#odml-qat">ODML QAT</a></li>
<li><a class="reference internal" href="#odml-conversion">ODML conversion</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="_static/tabs.js?v=3030b3cb"></script>
    </body>
</html>